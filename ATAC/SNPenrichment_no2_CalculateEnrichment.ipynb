{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "photographic-baseline",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/my-conda-envs/scanpy/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import rc_context\n",
    "import bbknn\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import rpy2\n",
    "import anndata\n",
    "from datetime import date\n",
    "from scipy.stats import binom_test\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import logging\n",
    "\n",
    "# YYYY-MM-DD\n",
    "today = date.today()\n",
    "today = today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-bernard",
   "metadata": {},
   "source": [
    "# Read in peaks matrix and tidy it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cosmetic-feeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:05:05:...reading peak file...takes 5 mins...\n",
      "15:09:40:...done.\n",
      "CPU times: user 4min 13s, sys: 19.2 s, total: 4min 32s\n",
      "Wall time: 4min 35s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr1:794932_795432</th>\n",
       "      <th>chr1:817104_817604</th>\n",
       "      <th>chr1:818775_819275</th>\n",
       "      <th>chr1:819697_820197</th>\n",
       "      <th>chr1:821364_821864</th>\n",
       "      <th>chr1:825517_826017</th>\n",
       "      <th>chr1:826623_827123</th>\n",
       "      <th>chr1:827307_827807</th>\n",
       "      <th>chr1:829896_830396</th>\n",
       "      <th>chr1:830664_831164</th>\n",
       "      <th>...</th>\n",
       "      <th>chrX:155755916_155756416</th>\n",
       "      <th>chrX:155767382_155767882</th>\n",
       "      <th>chrX:155768350_155768850</th>\n",
       "      <th>chrX:155794136_155794636</th>\n",
       "      <th>chrX:155820049_155820549</th>\n",
       "      <th>chrX:155874572_155875072</th>\n",
       "      <th>chrX:155880996_155881496</th>\n",
       "      <th>chrX:155881574_155882074</th>\n",
       "      <th>chrX:155888126_155888626</th>\n",
       "      <th>chrX:155894812_155895312</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine_grain</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAIT-like</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.004202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC1_vent</th>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.016364</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.007471</td>\n",
       "      <td>0.069370</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.027392</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.012807</td>\n",
       "      <td>0.007826</td>\n",
       "      <td>0.040199</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.001067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD8posT_cytox</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_plasma</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.065421</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 429828 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               chr1:794932_795432  chr1:817104_817604  chr1:818775_819275  \\\n",
       "fine_grain                                                                  \n",
       "MAIT-like                0.000000            0.000000            0.000000   \n",
       "B                        0.000000            0.004202            0.000000   \n",
       "PC1_vent                 0.000356            0.016364            0.006403   \n",
       "CD8posT_cytox            0.000000            0.000000            0.000000   \n",
       "B_plasma                 0.000000            0.000000            0.009346   \n",
       "\n",
       "               chr1:819697_820197  chr1:821364_821864  chr1:825517_826017  \\\n",
       "fine_grain                                                                  \n",
       "MAIT-like                0.000000            0.000000            0.000000   \n",
       "B                        0.000000            0.004202            0.000000   \n",
       "PC1_vent                 0.003202            0.002490            0.004269   \n",
       "CD8posT_cytox            0.000000            0.000000            0.000000   \n",
       "B_plasma                 0.000000            0.000000            0.000000   \n",
       "\n",
       "               chr1:826623_827123  chr1:827307_827807  chr1:829896_830396  \\\n",
       "fine_grain                                                                  \n",
       "MAIT-like                0.000000            0.063830            0.000000   \n",
       "B                        0.000000            0.046218            0.000000   \n",
       "PC1_vent                 0.007471            0.069370            0.000356   \n",
       "CD8posT_cytox            0.000000            0.031915            0.000000   \n",
       "B_plasma                 0.000000            0.056075            0.000000   \n",
       "\n",
       "               chr1:830664_831164  ...  chrX:155755916_155756416  \\\n",
       "fine_grain                         ...                             \n",
       "MAIT-like                0.000000  ...                  0.000000   \n",
       "B                        0.000000  ...                  0.000000   \n",
       "PC1_vent                 0.001423  ...                  0.001423   \n",
       "CD8posT_cytox            0.000000  ...                  0.000000   \n",
       "B_plasma                 0.000000  ...                  0.009346   \n",
       "\n",
       "               chrX:155767382_155767882  chrX:155768350_155768850  \\\n",
       "fine_grain                                                          \n",
       "MAIT-like                      0.000000                  0.000000   \n",
       "B                              0.004202                  0.004202   \n",
       "PC1_vent                       0.027392                  0.003557   \n",
       "CD8posT_cytox                  0.010638                  0.000000   \n",
       "B_plasma                       0.009346                  0.000000   \n",
       "\n",
       "               chrX:155794136_155794636  chrX:155820049_155820549  \\\n",
       "fine_grain                                                          \n",
       "MAIT-like                      0.021277                  0.000000   \n",
       "B                              0.000000                  0.000000   \n",
       "PC1_vent                       0.000356                  0.012807   \n",
       "CD8posT_cytox                  0.000000                  0.010638   \n",
       "B_plasma                       0.000000                  0.000000   \n",
       "\n",
       "               chrX:155874572_155875072  chrX:155880996_155881496  \\\n",
       "fine_grain                                                          \n",
       "MAIT-like                      0.000000                  0.010638   \n",
       "B                              0.004202                  0.016807   \n",
       "PC1_vent                       0.007826                  0.040199   \n",
       "CD8posT_cytox                  0.000000                  0.042553   \n",
       "B_plasma                       0.009346                  0.065421   \n",
       "\n",
       "               chrX:155881574_155882074  chrX:155888126_155888626  \\\n",
       "fine_grain                                                          \n",
       "MAIT-like                      0.000000                  0.000000   \n",
       "B                              0.004202                  0.004202   \n",
       "PC1_vent                       0.004269                  0.000711   \n",
       "CD8posT_cytox                  0.000000                  0.000000   \n",
       "B_plasma                       0.009346                  0.000000   \n",
       "\n",
       "               chrX:155894812_155895312  \n",
       "fine_grain                               \n",
       "MAIT-like                      0.000000  \n",
       "B                              0.004202  \n",
       "PC1_vent                       0.001067  \n",
       "CD8posT_cytox                  0.000000  \n",
       "B_plasma                       0.009346  \n",
       "\n",
       "[5 rows x 429828 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "    \n",
    "print(f'{current_time}:...reading peak file...takes 5 mins...')\n",
    "peaks=pd.read_csv('/nfs/team205/heart/anndata_objects/8regions/ArchR/project_output/PeakMatrix/Adult_celltype-by-Peak.csv')\n",
    "    \n",
    "peaks.columns = peaks.columns.str.replace('Unnamed: 0', 'fine_grain')\n",
    "peaks=peaks.set_index(peaks['fine_grain'])\n",
    "peaks=peaks.drop(columns=['fine_grain'])\n",
    "\n",
    "# replace characters which can break the code\n",
    "peaks.index=peaks.index.str.replace('+', 'pos')\n",
    "peaks.index=peaks.index.str.replace('/', '_or_')\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(f'{current_time}:...done.')\n",
    "peaks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "numerical-imperial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.11 s, sys: 120 ms, total: 4.23 s\n",
      "Wall time: 4.23 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>peak_window</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peak</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chr1:794932_795432</th>\n",
       "      <td>chr1</td>\n",
       "      <td>794932_795432</td>\n",
       "      <td>794932</td>\n",
       "      <td>795432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:817104_817604</th>\n",
       "      <td>chr1</td>\n",
       "      <td>817104_817604</td>\n",
       "      <td>817104</td>\n",
       "      <td>817604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:818775_819275</th>\n",
       "      <td>chr1</td>\n",
       "      <td>818775_819275</td>\n",
       "      <td>818775</td>\n",
       "      <td>819275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:819697_820197</th>\n",
       "      <td>chr1</td>\n",
       "      <td>819697_820197</td>\n",
       "      <td>819697</td>\n",
       "      <td>820197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   chrom    peak_window   start     end\n",
       "peak                                                   \n",
       "chr1:794932_795432  chr1  794932_795432  794932  795432\n",
       "chr1:817104_817604  chr1  817104_817604  817104  817604\n",
       "chr1:818775_819275  chr1  818775_819275  818775  819275\n",
       "chr1:819697_820197  chr1  819697_820197  819697  820197"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "all_peaks=pd.DataFrame(peaks.columns, columns=['peak'])\n",
    "all_peaks['chrom']=all_peaks['peak'].str.split(':',expand=True)[0]\n",
    "all_peaks['peak_window']=all_peaks['peak'].str.split(':',expand=True)[1]\n",
    "all_peaks['start']=all_peaks['peak_window'].str.split('_',expand=True)[0].astype(int)\n",
    "all_peaks['end']=all_peaks['peak_window'].str.split('_',expand=True)[1].astype(int)\n",
    "all_peaks=all_peaks.set_index(['peak'])\n",
    "all_peaks.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-boxing",
   "metadata": {},
   "source": [
    "# Set parameters for subsequent analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-sport",
   "metadata": {},
   "source": [
    "### Peak window width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "charitable-skating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjustment 0.0\n",
      "peak_width_500\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_peaks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m window_size_for_filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeak_width_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(window_size)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(window_size_for_filename)\n\u001b[0;32m----> 9\u001b[0m all_peaks[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mall_peaks\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m-\u001b[39mwindow_adjustment)\n\u001b[1;32m     10\u001b[0m all_peaks[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mall_peaks[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m+\u001b[39mwindow_adjustment)\n\u001b[1;32m     12\u001b[0m all_peaks\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_peaks' is not defined"
     ]
    }
   ],
   "source": [
    "# select a window size (bp) of interest (by default it is 500bp)\n",
    "\n",
    "window_size=500\n",
    "window_adjustment=(window_size-500)/2\n",
    "print('adjustment '+str(window_adjustment))\n",
    "window_size_for_filename='peak_width_'+str(window_size)\n",
    "print(window_size_for_filename)\n",
    "\n",
    "all_peaks['start']=all_peaks['start'].apply(lambda x: x-window_adjustment)\n",
    "all_peaks['end']=all_peaks['end'].apply(lambda x: x+window_adjustment)\n",
    "\n",
    "all_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-rider",
   "metadata": {},
   "source": [
    "### Set Cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of celltypes for subsequent analyses\n",
    "cell_types=peaks.index.unique().tolist()\n",
    "cell_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell_types=cell_types[25:27] # reduced while developing\n",
    "print(len(cell_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-stranger",
   "metadata": {},
   "source": [
    "### Set n_permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of permutations\n",
    "n_permutations=1000 # reduced while developing\n",
    "print(n_permutations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-drive",
   "metadata": {},
   "source": [
    "### Set threshold for binarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold for binarisation\n",
    "threshold=0.05\n",
    "threshold_for_filename=str(threshold).replace('.','p')\n",
    "print(threshold_for_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-barbados",
   "metadata": {},
   "source": [
    "### Set threshold for min number of index SNPs for a trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "western-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "too_few_snps_threshold=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-liberal",
   "metadata": {},
   "source": [
    "# Get SNP data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-bidder",
   "metadata": {},
   "source": [
    "### Set threshold for LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "processed-trash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0p9\n"
     ]
    }
   ],
   "source": [
    "LD_threshold=0.9 # threshold (r squared)\n",
    "LD_threshold_for_filename=str(LD_threshold).replace('.','p')\n",
    "print(LD_threshold_for_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "looking-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "snps_path='/nfs/team205/heart/JC_SNP_enrichment/8region/EBI_GWAS/index_snps/'\n",
    "snps_with_LD_path='/nfs/team205/heart/JC_SNP_enrichment/8region/EBI_GWAS/index_snps_with_LD/'\n",
    "snps_with_LD_with_pos_path='/nfs/team205/heart/JC_SNP_enrichment/8region/EBI_GWAS/index_snps_with_LD_with_pos/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-cemetery",
   "metadata": {},
   "source": [
    "## Get SNPs in LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "charitable-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are SNPs which cause errors when querying their genomic positions - usually because they no longer have assigned coordinates.\n",
    "# when such SNPs are found, add them to this list\n",
    "previous_problematic_snps=['rs9404922', 'rs5863461', 'rs140418671','rs10734649','rs7660850','rs7683747','rs59042994','rs35331282','rs5820605']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bibliographic-maintenance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:31:16: Fetching SNPs in LD\n",
      "NOT starting (already exists): EFO_0000537\n",
      "NOT starting (already exists): EFO_0000275\n",
      "NOT starting (already exists): EFO_0005053\n",
      "NOT starting (already exists): MONDO_0005178\n",
      "NOT starting (already exists): EFO_0005763\n",
      "NOT starting (already exists): EFO_0009285\n",
      "NOT starting (already exists): EFO_0009184\n",
      "NOT starting (already exists): EFO_0004573\n",
      "NOT starting (already exists): EFO_0021816\n",
      "NOT starting (already exists): EFO_0009783\n",
      "NOT starting (already exists): EFO_0004831\n",
      "NOT starting (already exists): EFO_0009277\n",
      "NOT starting (too few SNPs): MONDO_0000890, 1 index SNPs\n",
      "NOT starting (already exists): EFO_0006919\n",
      "NOT starting (already exists): EFO_1001482\n",
      "NOT starting (already exists): EFO_0005527\n",
      "NOT starting (already exists): EFO_OBSTRUCTIVE\n",
      "NOT starting (already exists): EFO_0004282\n",
      "NOT starting (already exists): EFO_0006828\n",
      "NOT starting (already exists): EFO_0004519\n",
      "NOT starting (already exists): EFO_0005524\n",
      "NOT starting (already exists): MONDO_0002078\n",
      "NOT starting (already exists): EFO_0009286\n",
      "NOT starting (already exists): EFO_0008469\n",
      "NOT starting (already exists): EFO_0008205\n",
      "NOT starting (already exists): EFO_0008432\n",
      "NOT starting (already exists): MONDO_0001823\n",
      "NOT starting (already exists): EFO_0003870\n",
      "NOT starting (already exists): EFO_0005055\n",
      "NOT starting (already exists): EFO_0006803\n",
      "NOT starting (already exists): EFO_0001666\n",
      "NOT starting (already exists): EFO_0009094\n",
      "NOT starting (already exists): EFO_0001361\n",
      "NOT starting (already exists): EFO_0005252\n",
      "NOT starting (already exists): EFO_0010272\n",
      "NOT starting (already exists): EFO_0005672\n",
      "NOT starting (already exists): EFO_RHLESION\n",
      "NOT starting (already exists): EFO_0007208\n",
      "NOT starting (already exists): EFO_0010977\n",
      "NOT starting (already exists): EFO_0008373\n",
      "NOT starting (already exists): MONDO_0005090\n",
      "NOT starting (too few SNPs): EFO_0010177, 1 index SNPs\n",
      "NOT starting (already exists): EFO_0010556\n",
      "NOT starting (already exists): EFO_SEPTAL\n",
      "NOT starting (already exists): EFO_0009289\n",
      "NOT starting (already exists): EFO_0006800\n",
      "NOT starting (too few SNPs): EFO_0004224, 1 index SNPs\n",
      "NOT starting (already exists): EFO_0000404\n",
      "NOT starting (already exists): EFO_0010071\n",
      "NOT starting (already exists): EFO_1002006\n",
      "NOT starting (already exists): EFO_0001645\n",
      "NOT starting (already exists): EFO_0004327\n",
      "NOT starting (already exists): EFO_0004885\n",
      "NOT starting (too few SNPs): MONDO_0021661, 1 index SNPs\n",
      "NOT starting (already exists): EFO_0010600\n",
      "NOT starting (already exists): EFO_0004462\n",
      "NOT starting (already exists): EFO_0000266\n",
      "NOT starting (already exists): EFO_0003912\n",
      "NOT starting (already exists): EFO_0004762\n",
      "NOT starting (already exists): EFO_0001425\n",
      "NOT starting (already exists): EFO_0000538\n",
      "NOT starting (already exists): EFO_0004718\n",
      "NOT starting (already exists): EFO_0005043\n",
      "NOT starting (already exists): EFO_0004761\n",
      "NOT starting (already exists): EFO_0005126\n",
      "NOT starting (already exists): EFO_0004644\n",
      "NOT starting (already exists): EFO_0004265\n",
      "NOT starting (already exists): EFO_0004286\n",
      "NOT starting (already exists): MONDO_0016820\n",
      "NOT starting (already exists): EFO_0005278\n",
      "NOT starting (already exists): EFO_0005939\n",
      "NOT starting (already exists): EFO_0008379\n",
      "NOT starting (already exists): EFO_0009552\n",
      "NOT starting (already exists): EFO_0005239\n",
      "NOT starting (already exists): EFO_0005269\n",
      "NOT starting (too few SNPs): EFO_0008583, 1 index SNPs\n",
      "NOT starting (already exists): EFO_0007928\n",
      "NOT starting (already exists): EFO_0005207\n",
      "NOT starting (already exists): EFO_0009953\n",
      "NOT starting (already exists): EFO_0006903\n",
      "NOT starting (already exists): EFO_0007741\n",
      "NOT starting (already exists): EFO_0003875\n",
      "NOT starting (already exists): EFO_0006795\n",
      "NOT starting (already exists): EFO_0000407\n",
      "NOT starting (already exists): EFO_0005095\n",
      "NOT starting (already exists): EFO_0005196\n",
      "NOT starting (already exists): EFO_0009276\n",
      "NOT starting (already exists): EFO_0010273\n",
      "NOT starting (too few SNPs): EFO_0600032, 1 index SNPs\n",
      "NOT starting (already exists): EFO_0010178\n",
      "NOT starting (already exists): EFO_0004311\n",
      "NOT starting (already exists): EFO_0020863\n",
      "NOT starting (already exists): MONDO_0001134\n",
      "NOT starting (too few SNPs): EFO_1001395, 1 index SNPs\n",
      "NOT starting (already exists): EFO_0000612\n",
      "NOT starting (already exists): EFO_0003144\n",
      "NOT starting (already exists): EFO_0020942\n",
      "NOT starting (already exists): HP_0030680\n",
      "NOT starting (already exists): HP_0001634\n",
      "NOT starting (too few SNPs): EFO_0600026, 1 index SNPs\n",
      "NOT starting (already exists): EFO_1001017\n",
      "NOT starting (already exists): EFO_0004520\n",
      "NOT starting (already exists): EFO_0004328\n",
      "NOT starting (already exists): EFO_0005416\n",
      "NOT starting (already exists): EFO_0600035\n",
      "NOT starting (already exists): MONDO_0015263\n",
      "NOT starting (already exists): EFO_0007742\n",
      "NOT starting (already exists): EFO_0010820\n",
      "NOT starting (already exists): EFO_0008204\n",
      "NOT starting (already exists): EFO_0008398\n",
      "NOT starting (already exists): EFO_1001976\n",
      "NOT starting (already exists): EFO_0006791\n",
      "NOT starting (already exists): EFO_NOS\n",
      "NOT starting (already exists): EFO_0006902\n",
      "NOT starting (already exists): EFO_0009275\n",
      "NOT starting (already exists): EFO_0020101\n",
      "NOT starting (already exists): EFO_1000059\n",
      "NOT starting (already exists): EFO_0006790\n",
      "NOT starting (already exists): EFO_0005054\n",
      "NOT starting (already exists): EFO_1002000\n",
      "NOT starting (already exists): EFO_0008536\n",
      "NOT starting (already exists): EFO_0021817\n",
      "NOT starting (already exists): EFO_ALLCHD\n",
      "NOT starting (too few SNPs): EFO_0004772, 1 index SNPs\n",
      "NOT starting (already exists): Orphanet_136\n",
      "NOT starting (already exists): EFO_0007885\n",
      "NOT starting (already exists): MONDO_0010679\n",
      "NOT starting (already exists): EFO_0004985\n",
      "NOT starting (already exists): EFO_0008206\n",
      "NOT starting (already exists): EFO_0008365\n",
      "NOT starting (already exists): EFO_0008468\n",
      "NOT starting (already exists): EFO_0006523\n",
      "NOT starting (already exists): EFO_1001132\n",
      "NOT starting (too few SNPs): HP_0001760, 1 index SNPs\n",
      "NOT starting (already exists): EFO_0004791\n",
      "NOT starting (already exists): EFO_0003827\n",
      "NOT starting (too few SNPs): EFO_0004225, 1 index SNPs\n",
      "NOT starting (already exists): EFO_0005037\n",
      "NOT starting (already exists): EFO_0007787\n",
      "NOT starting (already exists): EFO_0000713\n",
      "NOT starting (already exists): EFO_LHLESION\n",
      "NOT starting (already exists): EFO_1001857\n",
      "NOT starting (already exists): EFO_1001161\n",
      "NOT starting (already exists): EFO_0006920\n",
      "NOT starting (already exists): EFO_1001459\n",
      "NOT starting (already exists): EFO_0005529\n",
      "NOT starting (already exists): EFO_0005942\n",
      "NOT starting (already exists): EFO_0000712\n",
      "NOT starting (already exists): EFO_1000882\n",
      "NOT starting (too few SNPs): EFO_0004572, 1 index SNPs\n",
      "NOT starting (already exists): EFO_0005243\n",
      "NOT starting (already exists): EFO_0021814\n",
      "NOT starting (already exists): EFO_0003914\n",
      "NOT starting (already exists): EFO_0020865\n",
      "NOT starting (too few SNPs): EFO_0021792, 1 index SNPs\n",
      "NOT starting (already exists): EFO_0004789\n",
      "NOT starting (already exists): EFO_0004517\n",
      "NOT starting (already exists): MONDO_0005277\n",
      "NOT starting (already exists): EFO_0008537\n",
      "NOT starting (already exists): EFO_1001483\n",
      "NOT starting (already exists): EFO_0021788\n",
      "NOT starting (already exists): EFO_0009609\n",
      "NOT starting (already exists): EFO_0006900\n",
      "NOT starting (already exists): EFO_0004277\n",
      "NOT starting (already exists): EFO_0004860\n",
      "NOT starting (already exists): EFO_0004682\n",
      "NOT starting (too few SNPs): EFO_0005307, 1 index SNPs\n",
      "NOT starting (already exists): EFO_0004351\n",
      "NOT starting (already exists): EFO_0004214\n",
      "NOT starting (too few SNPs): EFO_1001495, 1 index SNPs\n",
      "NOT starting (already exists): EFO_0000668\n",
      "NOT starting (already exists): EFO_0600077\n",
      "NOT starting (already exists): EFO_0006501\n",
      "NOT starting (already exists): EFO_1000881\n",
      "NOT starting (already exists): EFO_0005938\n",
      "NOT starting (too few SNPs): EFO_0004724, 1 index SNPs\n",
      "NOT starting (already exists): EFO_0009551\n",
      "NOT starting (already exists): EFO_0021815\n",
      "NOT starting (already exists): EFO_0005128\n",
      "NOT starting (already exists): EFO_1001504\n",
      "NOT starting (already exists): MONDO_0019438\n",
      "NOT starting (already exists): EFO_0009952\n",
      "NOT starting (already exists): MONDO_0005475\n",
      "NOT starting (already exists): EFO_0004534\n",
      "NOT starting (already exists): EFO_0008003\n",
      "NOT starting (already exists): EFO_0005532\n",
      "NOT starting (already exists): EFO_0004507\n",
      "NOT starting (already exists): MONDO_0000153\n",
      "NOT starting (already exists): EFO_0000717\n",
      "NOT starting (already exists): EFO_0004326\n",
      "NOT starting (already exists): EFO_0005094\n",
      "NOT starting (already exists): EFO_0005918\n",
      "NOT starting (already exists): EFO_VASCULAR\n",
      "NOT starting (already exists): EFO_0004745\n",
      "NOT starting (already exists): EFO_0006522\n",
      "NOT starting (already exists): EFO_0021787\n",
      "NOT starting (already exists): EFO_0005669\n",
      "NOT starting (already exists): EFO_1001209\n",
      "NOT starting (too few SNPs): EFO_0000373, 1 index SNPs\n",
      "NOT starting (already exists): EFO_0005251\n",
      "NOT starting (already exists): EFO_0004578\n",
      "NOT starting (already exists): EFO_1001493\n",
      "NOT starting (already exists): EFO_0004278\n",
      "NOT starting (already exists): EFO_0004269\n",
      "NOT starting (already exists): EFO_1000883\n",
      "NOT starting (already exists): EFO_0009185\n",
      "NOT starting (already exists): EFO_0600025\n",
      "19:31:17: Finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>errorcodes_e_index</th>\n",
       "      <th>errorcodes_file_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [errorcodes_e_index, errorcodes_file_index]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(snps_with_LD_path,\n",
    "           exist_ok=True) # makes the directory\n",
    "\n",
    "too_few_snps=[]\n",
    "\n",
    "errorcodes_e_index=[]\n",
    "errorcodes_file_index=[]\n",
    "problematic_snps=[]\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(f'{current_time}: Fetching SNPs in LD')\n",
    "\n",
    "index_snp_files=os.listdir(snps_path)\n",
    "\n",
    "\n",
    "for index_snp_file in index_snp_files:\n",
    "    \n",
    "    efo_id=index_snp_file.split('_')[0]+'_'+index_snp_file.split('_')[1]\n",
    "    \n",
    "    if os.path.isfile(f'{snps_with_LD_path}{efo_id}_with_SNPs_in_LD_{LD_threshold_for_filename}.csv')==False:\n",
    "    \n",
    "        snps_df=pd.read_csv(f'{snps_path}{index_snp_file}')\n",
    "\n",
    "        if len(snps_df)>too_few_snps_threshold:\n",
    "            \n",
    "            try:\n",
    "\n",
    "                now = datetime.now()\n",
    "                current_time = now.strftime(\"%H:%M:%S\")\n",
    "                print(f'{current_time}: Starting '+index_snp_file+', '+str(len(snps_df))+' index SNPs')\n",
    "\n",
    "                index_simplified_classification=[]\n",
    "                index_phenotype=[]\n",
    "                index_study=[]\n",
    "                index_snps=[]\n",
    "                index_chrom=[]\n",
    "                index_pos=[]\n",
    "                population_name=[]\n",
    "                tagged_snps=[]\n",
    "                tagged_r2=[]\n",
    "\n",
    "                for i in range(len(snps_df[rsid_col])):\n",
    "\n",
    "                    rsid=snps_df[rsid_col][i]\n",
    "                    \n",
    "                    if rsid.startswith('rs') and rsid not in previous_problematic_snps:\n",
    "                        \n",
    "                        try:\n",
    "\n",
    "                            server = \"http://rest.ensembl.org\"\n",
    "                            ext = f\"/ld/human/{rsid}/1000GENOMES:phase_3:EUR?r2={LD_threshold};window_size=500\"\n",
    "\n",
    "                            r = requests.get(server+ext, headers={ \"Content-Type\" : \"application/json\"})\n",
    "\n",
    "                            if not r.ok:\n",
    "                              r.raise_for_status()\n",
    "                              sys.exit()\n",
    "\n",
    "                            decoded = r.json()\n",
    "\n",
    "                            if len(decoded)>0: # sometimes there will be no SNPs in LD\n",
    "\n",
    "                                for j in range(len(decoded)):\n",
    "                                    index_snps.append(snps_df[rsid_col][i])\n",
    "                                    index_chrom.append(snps_df[chrom][i])\n",
    "                                    index_pos.append(snps_df[pos][i])\n",
    "                                    population_name.append(decoded[j]['population_name'])\n",
    "                                    tagged_snps.append(decoded[j]['variation2'])\n",
    "                                    tagged_r2.append(decoded[j]['r2'])\n",
    "\n",
    "                            else:\n",
    "                                index_snps.append(snps_df[rsid_col][i])\n",
    "                                index_chrom.append(snps_df[chrom][i])\n",
    "                                index_pos.append(snps_df[pos][i])\n",
    "                                population_name.append('NA')\n",
    "                                tagged_snps.append('NA')\n",
    "                                tagged_r2.append('NA')\n",
    "\n",
    "                            # for each index SNP add an extra row with the index SNP id, chrom, and pos in the tagged_SNPS columns (even though they are the index SNP) - makes later reading easier\n",
    "                            index_snps.append(snps_df[rsid_col][i])\n",
    "                            index_chrom.append(snps_df[chrom][i])\n",
    "                            index_pos.append(snps_df[pos][i])\n",
    "                            population_name.append('NA')\n",
    "                            tagged_snps.append(rsid)\n",
    "                            tagged_r2.append('index')\n",
    "\n",
    "                            output_dict={\n",
    "                                'index_snps':index_snps,\n",
    "                                'index_chrom':index_chrom,\n",
    "                                'index_pos':index_pos,\n",
    "                                'population_name':population_name,\n",
    "                                'tagged_snps':tagged_snps,\n",
    "                                'tagged_r2':tagged_r2}\n",
    "\n",
    "                            output=pd.DataFrame(output_dict)\n",
    "\n",
    "                        except Exception as problematic_snp:\n",
    "                            print('problematic snp: '+rsid+' ('+file+')')\n",
    "                            problematic_snps_error.append(e)\n",
    "                            problematic_snps.append(rsid)\n",
    "                            problematic_snps_file.append(index_snp_file)\n",
    "\n",
    "                    # remove rows where no tagged SNP could be found\n",
    "                    output = output[output[\"tagged_snps\"] != \"NA\"]\n",
    "\n",
    "                    output.to_csv(f'{snps_with_LD_path}{efo_id}_with_SNPs_in_LD_{LD_threshold_for_filename}.csv')\n",
    "                    \n",
    "            except Exception as e:\n",
    "                # Log the error\n",
    "                errorcodes_e_index.append(e)\n",
    "                errorcodes_file_index.append(index_snp_file)\n",
    "                \n",
    "        else:\n",
    "            too_few_snps.append(index_snp_file)\n",
    "            print('NOT starting (too few SNPs): '+efo_id+', '+str(len(snps_df))+' index SNPs')\n",
    "    else:\n",
    "        print('NOT starting (already exists): '+efo_id)\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(f'{current_time}: Finished')\n",
    "\n",
    "error_dict={\n",
    "    'errorcodes_e_index':errorcodes_e_index,\n",
    "    'errorcodes_file_index':errorcodes_file_index}\n",
    "\n",
    "pd.DataFrame(error_dict)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-submission",
   "metadata": {},
   "source": [
    "## Get coordinates of SNPs in LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "narrow-television",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:31:17: Fetching genomic coordinates for SNPs in LD\n",
      "NOT starting (already exists): EFO_0004644_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0009185_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005524_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005207_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005669_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0000266_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0000407_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004277_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0007208_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0020101_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004462_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005243_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005126_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_RHLESION_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0021814_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004831_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0021816_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0009276_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0008373_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0600035_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005532_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005939_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004761_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004326_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0008003_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004507_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_1001483_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_SEPTAL_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004885_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_1001504_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005918_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0008468_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0007742_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0021788_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0006523_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005251_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0006803_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005037_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0008469_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0001666_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): MONDO_0016820_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0000717_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005529_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_1000882_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0006920_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_1001161_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0009286_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0000275_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0006791_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0003912_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0010178_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0009275_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0009609_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0010977_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0010820_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004682_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004860_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): MONDO_0019438_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): MONDO_0001823_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004520_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_ALLCHD_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0001645_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0000404_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): MONDO_0010679_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0003914_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): MONDO_0005277_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005094_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_NOS_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0010556_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0000713_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0010272_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0000537_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0000612_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004327_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0006795_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_1001132_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004985_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005672_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005053_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_1002006_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0003870_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005055_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0003875_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_VASCULAR_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004214_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0009289_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0009277_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004278_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): MONDO_0000153_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_1000881_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005938_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_1001017_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_1001459_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004265_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0021787_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0008537_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0007741_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0008536_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0008205_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0021817_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_1000059_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004789_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0008204_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0008365_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0006790_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0020865_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005043_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_LHLESION_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0001361_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0007928_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0021815_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004791_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0007885_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0007787_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): Orphanet_136_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004578_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005252_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0006903_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0009552_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005416_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0000668_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005269_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004534_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005196_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0600025_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005128_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0006800_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): HP_0030680_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_1001482_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004269_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0009094_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0000712_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0600077_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0020942_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): MONDO_0005178_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0009551_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005942_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): MONDO_0015263_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0009783_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0006522_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005095_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0009953_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): HP_0001634_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_1001493_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0006828_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005278_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004517_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0009184_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005054_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005763_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0010071_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004745_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_1001857_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_OBSTRUCTIVE_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0010600_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0003144_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_1000883_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0006501_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_1002000_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0008432_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004573_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005239_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0008379_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004282_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0005527_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0001425_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004351_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004311_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0006919_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0003827_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0000538_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0008398_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): MONDO_0005475_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0020863_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004762_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): MONDO_0001134_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004519_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0010273_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0006900_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004286_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004328_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0009952_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): MONDO_0005090_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): MONDO_0002078_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0004718_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0009285_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0006902_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_0008206_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_1001976_with_SNPs_in_LD_0p9.csv\n",
      "NOT starting (already exists): EFO_1001209_with_SNPs_in_LD_0p9.csv\n",
      "19:31:17: Finished\n",
      "CPU times: user 17.7 ms, sys: 592 Âµs, total: 18.2 ms\n",
      "Wall time: 314 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "errorcodes_e_LD=[]\n",
    "errorcodes_file_LD=[]\n",
    "problematic_snps=[]\n",
    "problematic_snps_file=[]\n",
    "problematic_snps_error=[]\n",
    "\n",
    "\n",
    "os.makedirs(snps_with_LD_with_pos_path,\n",
    "           exist_ok=True) # makes the directory\n",
    "\n",
    "files=os.listdir(snps_with_LD_path)\n",
    "\n",
    "files=[f for f in files if f\"{LD_threshold_for_filename}\" in f]\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(f'{current_time}: Fetching genomic coordinates for SNPs in LD')\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    efo_id=file.split('_')[0]+'_'+file.split('_')[1]\n",
    "    \n",
    "    if os.path.isfile(f'{snps_with_LD_with_pos_path}{efo_id}_with_SNPs_in_LD_{LD_threshold_for_filename}_with_pos.csv')==False:\n",
    "        \n",
    "        try:\n",
    "\n",
    "            snps_df=pd.read_csv(f'{snps_with_LD_path}{file}')\n",
    "\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%H:%M:%S\")\n",
    "            print(f'{current_time}: Starting: '+file+', '+str(len(snps_df))+' total SNPs')\n",
    "\n",
    "            # lists which are needed for each output\n",
    "            tagged_pos=[]\n",
    "            tagged_chrom=[]\n",
    "\n",
    "            for snp in range(len(snps_df['tagged_snps'])):\n",
    "\n",
    "                rsid_of_interest=snps_df['tagged_snps'][snp]\n",
    "                \n",
    "                if rsid_of_interest.startswith('rs') and rsid_of_interest not in previous_problematic_snps:\n",
    "                    \n",
    "                    try:\n",
    "                        \n",
    "                        server = \"https://rest.ensembl.org\"\n",
    "                        ext = f\"/variation/human/{rsid_of_interest}?\"\n",
    "                        r = requests.get(server+ext, headers={ \"Content-Type\" : \"application/json\"})\n",
    "                        decoded = r.json()\n",
    "\n",
    "                        if len(decoded)>0 and \"mappings\" in decoded:\n",
    "                            tagged_pos.append(decoded['mappings'][0]['start'])\n",
    "                            tagged_chrom.append(decoded['mappings'][0]['seq_region_name'])\n",
    "                        else:\n",
    "                            tagged_pos.append(\"NA\")\n",
    "                            tagged_chrom.append(\"NA\")\n",
    "                    except Exception as e:\n",
    "                            print('problematic snp: '+rsid_of_interest+' ('+file+')')\n",
    "                            problematic_snps_error.append(e)\n",
    "                            problematic_snps.append(rsid_of_interest)\n",
    "                            problematic_snps_file.append(file)\n",
    "                            tagged_pos.append(\"NA\")\n",
    "                            tagged_chrom.append(\"NA\")\n",
    "                else:\n",
    "                    tagged_pos.append(\"NA\")\n",
    "                    tagged_chrom.append(\"NA\")\n",
    "            snps_df['tagged_pos']=tagged_pos\n",
    "            snps_df['tagged_chrom']=tagged_chrom\n",
    "            snps_df.to_csv(f'{snps_with_LD_with_pos_path}{efo_id}_with_SNPs_in_LD_{LD_threshold_for_filename}_with_pos.csv')\n",
    "\n",
    "        except Exception as e:\n",
    "            # Log the error\n",
    "            errorcodes_e_LD.append(e)\n",
    "            errorcodes_file_LD.append(file)\n",
    "            tagged_pos.append(\"NA\")\n",
    "            tagged_chrom.append(\"NA\")\n",
    "\n",
    "    else:\n",
    "        print('NOT starting (already exists): '+file)\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(f'{current_time}: Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-mount",
   "metadata": {},
   "source": [
    "# Make some SNP table metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "legitimate-diamond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.6 s, sys: 87.6 ms, total: 1.69 s\n",
      "Wall time: 2.14 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>efo_term</th>\n",
       "      <th>n_SNPs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efo_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MONDO_0005090</th>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>50656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFO_0005763</th>\n",
       "      <td>pulse pressure measurement</td>\n",
       "      <td>39352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFO_0004761</th>\n",
       "      <td>uric acid measurement</td>\n",
       "      <td>12256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFO_0004682</th>\n",
       "      <td>QT interval</td>\n",
       "      <td>10386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFO_0000537</th>\n",
       "      <td>hypertension</td>\n",
       "      <td>9960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HP_0030680</th>\n",
       "      <td>abnormality of cardiovascular system morphology</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONDO_0000153</th>\n",
       "      <td>transposition of the great arteries</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFO_0007741</th>\n",
       "      <td>R wave amplitude</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFO_0006795</th>\n",
       "      <td>serum VEGFR2 concentration measurement</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFO_RHLESION</th>\n",
       "      <td>RH</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      efo_term  n_SNPs\n",
       "efo_id                                                                \n",
       "MONDO_0005090                                    schizophrenia   50656\n",
       "EFO_0005763                         pulse pressure measurement   39352\n",
       "EFO_0004761                              uric acid measurement   12256\n",
       "EFO_0004682                                        QT interval   10386\n",
       "EFO_0000537                                       hypertension    9960\n",
       "...                                                        ...     ...\n",
       "HP_0030680     abnormality of cardiovascular system morphology       6\n",
       "MONDO_0000153              transposition of the great arteries       5\n",
       "EFO_0007741                                   R wave amplitude       3\n",
       "EFO_0006795             serum VEGFR2 concentration measurement       3\n",
       "EFO_RHLESION                                                RH       2\n",
       "\n",
       "[190 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# make a table of metadata about the SNP files\n",
    "md_efo_ids=[]\n",
    "md_efo_terms=[]\n",
    "md_n_SNPs=[]\n",
    "\n",
    "\n",
    "files=os.listdir(snps_with_LD_with_pos_path)\n",
    "\n",
    "files=[f for f in files if f\"{LD_threshold_for_filename}\" in f]\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    efo_id=str(file.split('_')[0])+'_'+str(file.split('_')[1])\n",
    "    md_efo_ids.append(efo_id)\n",
    "                      \n",
    "    snps_df=pd.read_csv(f'{snps_with_LD_with_pos_path}{file}')\n",
    "    snps_df=snps_df.set_index('tagged_snps')\n",
    "    \n",
    "    snps_df[\"chrom\"] = snps_df['tagged_chrom'].apply(lambda x: 'chr'+str(x)).str.split('.',expand=True)[0] # creates a new 'chrom' column and should work even for X or M chromosomes\n",
    "\n",
    "    md_n_SNPs.append(len(snps_df))\n",
    "    \n",
    "    \n",
    "    original_snp_files=os.listdir(snps_path)\n",
    "    efo_term=[file for file in original_snp_files if f\"{efo_id}\" in file]\n",
    "    efo_term=efo_term[0].split('_')[2]\n",
    "    md_efo_terms.append(efo_term)\n",
    "\n",
    "md_dict={\n",
    "    'efo_id':md_efo_ids,\n",
    "    'efo_term':md_efo_terms,\n",
    "    'n_SNPs':md_n_SNPs\n",
    "}\n",
    "\n",
    "\n",
    "SNP_md=pd.DataFrame(md_dict)\n",
    "SNP_md=SNP_md.set_index('efo_id')\n",
    "\n",
    "SNP_md.sort_values('n_SNPs',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "matched-cleanup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    }
   ],
   "source": [
    "# get final list of efo_ids to be used in analysis\n",
    "efo_ids=SNP_md.index.tolist()\n",
    "n_traits=len(efo_ids)\n",
    "print(n_traits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-charm",
   "metadata": {},
   "source": [
    "# Evaluate whether SNPs are found in peaks using the all_peaks file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sunrise-murray",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...SNPs in peaks file already exists, reading it in...\n",
      "CPU times: user 4.18 s, sys: 316 ms, total: 4.5 s\n",
      "Wall time: 4.51 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>peak_window</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>EFO_0010977</th>\n",
       "      <th>EFO_0004520</th>\n",
       "      <th>MONDO_0001823</th>\n",
       "      <th>EFO_0004286</th>\n",
       "      <th>EFO_0004519</th>\n",
       "      <th>EFO_0005527</th>\n",
       "      <th>...</th>\n",
       "      <th>EFO_0005918</th>\n",
       "      <th>EFO_0004328</th>\n",
       "      <th>EFO_VASCULAR</th>\n",
       "      <th>EFO_0004791</th>\n",
       "      <th>EFO_0005053</th>\n",
       "      <th>EFO_0006900</th>\n",
       "      <th>EFO_0010600</th>\n",
       "      <th>EFO_0005054</th>\n",
       "      <th>EFO_0000717</th>\n",
       "      <th>EFO_0005043</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peak</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chr1:794932_795432</th>\n",
       "      <td>chr1</td>\n",
       "      <td>794932_795432</td>\n",
       "      <td>794932.0</td>\n",
       "      <td>795432.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:817104_817604</th>\n",
       "      <td>chr1</td>\n",
       "      <td>817104_817604</td>\n",
       "      <td>817104.0</td>\n",
       "      <td>817604.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:818775_819275</th>\n",
       "      <td>chr1</td>\n",
       "      <td>818775_819275</td>\n",
       "      <td>818775.0</td>\n",
       "      <td>819275.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:819697_820197</th>\n",
       "      <td>chr1</td>\n",
       "      <td>819697_820197</td>\n",
       "      <td>819697.0</td>\n",
       "      <td>820197.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:821364_821864</th>\n",
       "      <td>chr1</td>\n",
       "      <td>821364_821864</td>\n",
       "      <td>821364.0</td>\n",
       "      <td>821864.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:155874572_155875072</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155874572_155875072</td>\n",
       "      <td>155874572.0</td>\n",
       "      <td>155875072.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:155880996_155881496</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155880996_155881496</td>\n",
       "      <td>155880996.0</td>\n",
       "      <td>155881496.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:155881574_155882074</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155881574_155882074</td>\n",
       "      <td>155881574.0</td>\n",
       "      <td>155882074.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:155888126_155888626</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155888126_155888626</td>\n",
       "      <td>155888126.0</td>\n",
       "      <td>155888626.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:155894812_155895312</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155894812_155895312</td>\n",
       "      <td>155894812.0</td>\n",
       "      <td>155895312.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>429828 rows Ã— 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         chrom          peak_window        start          end  \\\n",
       "peak                                                                            \n",
       "chr1:794932_795432        chr1        794932_795432     794932.0     795432.0   \n",
       "chr1:817104_817604        chr1        817104_817604     817104.0     817604.0   \n",
       "chr1:818775_819275        chr1        818775_819275     818775.0     819275.0   \n",
       "chr1:819697_820197        chr1        819697_820197     819697.0     820197.0   \n",
       "chr1:821364_821864        chr1        821364_821864     821364.0     821864.0   \n",
       "...                        ...                  ...          ...          ...   \n",
       "chrX:155874572_155875072  chrX  155874572_155875072  155874572.0  155875072.0   \n",
       "chrX:155880996_155881496  chrX  155880996_155881496  155880996.0  155881496.0   \n",
       "chrX:155881574_155882074  chrX  155881574_155882074  155881574.0  155882074.0   \n",
       "chrX:155888126_155888626  chrX  155888126_155888626  155888126.0  155888626.0   \n",
       "chrX:155894812_155895312  chrX  155894812_155895312  155894812.0  155895312.0   \n",
       "\n",
       "                          EFO_0010977  EFO_0004520  MONDO_0001823  \\\n",
       "peak                                                                \n",
       "chr1:794932_795432                  0            0              0   \n",
       "chr1:817104_817604                  0            0              0   \n",
       "chr1:818775_819275                  0            0              0   \n",
       "chr1:819697_820197                  0            0              0   \n",
       "chr1:821364_821864                  0            0              0   \n",
       "...                               ...          ...            ...   \n",
       "chrX:155874572_155875072            0            0              0   \n",
       "chrX:155880996_155881496            0            0              0   \n",
       "chrX:155881574_155882074            0            0              0   \n",
       "chrX:155888126_155888626            0            0              0   \n",
       "chrX:155894812_155895312            0            0              0   \n",
       "\n",
       "                          EFO_0004286  EFO_0004519  EFO_0005527  ...  \\\n",
       "peak                                                             ...   \n",
       "chr1:794932_795432                  0            0            0  ...   \n",
       "chr1:817104_817604                  0            0            0  ...   \n",
       "chr1:818775_819275                  0            0            0  ...   \n",
       "chr1:819697_820197                  0            0            0  ...   \n",
       "chr1:821364_821864                  0            0            0  ...   \n",
       "...                               ...          ...          ...  ...   \n",
       "chrX:155874572_155875072            0            0            0  ...   \n",
       "chrX:155880996_155881496            0            0            0  ...   \n",
       "chrX:155881574_155882074            0            0            0  ...   \n",
       "chrX:155888126_155888626            0            0            0  ...   \n",
       "chrX:155894812_155895312            0            0            0  ...   \n",
       "\n",
       "                          EFO_0005918  EFO_0004328  EFO_VASCULAR  EFO_0004791  \\\n",
       "peak                                                                            \n",
       "chr1:794932_795432                  0            0             0            0   \n",
       "chr1:817104_817604                  0            0             0            0   \n",
       "chr1:818775_819275                  0            0             0            0   \n",
       "chr1:819697_820197                  0            0             0            0   \n",
       "chr1:821364_821864                  0            0             0            0   \n",
       "...                               ...          ...           ...          ...   \n",
       "chrX:155874572_155875072            0            0             0            0   \n",
       "chrX:155880996_155881496            0            0             0            0   \n",
       "chrX:155881574_155882074            0            0             0            0   \n",
       "chrX:155888126_155888626            0            0             0            0   \n",
       "chrX:155894812_155895312            0            0             0            0   \n",
       "\n",
       "                          EFO_0005053  EFO_0006900  EFO_0010600  EFO_0005054  \\\n",
       "peak                                                                           \n",
       "chr1:794932_795432                  0            0            0            0   \n",
       "chr1:817104_817604                  0            0            0            0   \n",
       "chr1:818775_819275                  0            0            0            0   \n",
       "chr1:819697_820197                  0            0            0            0   \n",
       "chr1:821364_821864                  0            0            0            0   \n",
       "...                               ...          ...          ...          ...   \n",
       "chrX:155874572_155875072            0            0            0            0   \n",
       "chrX:155880996_155881496            0            0            0            0   \n",
       "chrX:155881574_155882074            0            0            0            0   \n",
       "chrX:155888126_155888626            0            0            0            0   \n",
       "chrX:155894812_155895312            0            0            0            0   \n",
       "\n",
       "                          EFO_0000717  EFO_0005043  \n",
       "peak                                                \n",
       "chr1:794932_795432                  0            0  \n",
       "chr1:817104_817604                  0            0  \n",
       "chr1:818775_819275                  0            0  \n",
       "chr1:819697_820197                  0            0  \n",
       "chr1:821364_821864                  0            0  \n",
       "...                               ...          ...  \n",
       "chrX:155874572_155875072            0            0  \n",
       "chrX:155880996_155881496            0            0  \n",
       "chrX:155881574_155882074            0            0  \n",
       "chrX:155888126_155888626            0            0  \n",
       "chrX:155894812_155895312            0            0  \n",
       "\n",
       "[429828 rows x 194 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Add on a column for each trait, indicating whether a SNP from that trait falls within a peak. This file varies with the which traits are assessed\n",
    "\n",
    "\n",
    "all_peaks_path='/nfs/team205/heart/JC_SNP_enrichment/8region/EBI_GWAS/SNP_mapped_to_peaks/'\n",
    "\n",
    "os.makedirs(all_peaks_path,\n",
    "           exist_ok=True) # makes the directory\n",
    "\n",
    "\n",
    "files=os.listdir(snps_with_LD_with_pos_path)\n",
    "\n",
    "if os.path.isfile(f'{all_peaks_path}all_peaks_with_SNPs_for_{n_traits}_traits_incremental.csv')==False:\n",
    "    print(f'...a SNPs in peaks file for this set of traits is NOT found, making one now...')\n",
    "    print(str(len(efo_ids))+' traits in total')\n",
    "    for efo_id in efo_ids:\n",
    "\n",
    "            file = [f for f in files if f\"{efo_id}\" in f]\n",
    "            file = str(file[0])\n",
    "\n",
    "            snps_df=pd.read_csv(f'{snps_with_LD_with_pos_path}{file}')\n",
    "            snps_df=snps_df.set_index('tagged_snps')\n",
    "\n",
    "            snps_df[\"chrom\"] = snps_df[\"tagged_chrom\"].apply(lambda x: 'chr'+str(x)).str.split('.',expand=True)[0] # creates a new 'chrom' column *with chr prefix* and should work even for X or M chrosomes\n",
    "\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%H:%M:%S\")\n",
    "            print(f'{current_time}_{efo_id}:...evaluating for SNPs in peaks...')\n",
    "\n",
    "            all_peaks[efo_id]=0\n",
    "            for snp in range(len(snps_df[\"tagged_chrom\"])): # This loop incrementally adds 1 if there is a SNP within a peak (open or closed)\n",
    "                all_peaks[efo_id][\n",
    "                    (all_peaks['chrom'] == snps_df[\"chrom\"][snp])\n",
    "                    &\n",
    "                    (all_peaks['start'] <= snps_df['tagged_pos'][snp])\n",
    "                    &\n",
    "                    (all_peaks['end'] >= snps_df['tagged_pos'][snp])\n",
    "                ]+=1 # Adds one for each SNP which falls inside a peak\n",
    "    all_peaks.to_csv(f'{all_peaks_path}all_peaks_with_SNPs_for_{n_traits}_traits_incremental.csv')\n",
    "else:\n",
    "    all_peaks=pd.read_csv(f'{all_peaks_path}all_peaks_with_SNPs_for_{n_traits}_traits_incremental.csv',index_col='peak')\n",
    "    print(f'...SNPs in peaks file already exists, reading it in...')\n",
    "\n",
    "all_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "digital-literature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EFO_0010977: 2\n",
      "EFO_0004520: 34\n",
      "MONDO_0001823: 8\n",
      "EFO_0004286: 649\n",
      "EFO_0004519: 1\n",
      "EFO_0005527: 41\n",
      "EFO_0009952: 1\n",
      "EFO_0009609: 4\n",
      "EFO_0020101: 4\n",
      "EFO_1001976: 280\n",
      "HP_0001634: 112\n",
      "EFO_SEPTAL: 0\n",
      "EFO_0009094: 22\n",
      "EFO_0005416: 13\n",
      "EFO_0005055: 775\n",
      "EFO_0005532: 23\n",
      "EFO_0001361: 11\n",
      "EFO_0005669: 14\n",
      "EFO_0000266: 32\n",
      "MONDO_0005090: 4102\n",
      "EFO_0010820: 4\n",
      "EFO_0020863: 13\n",
      "EFO_0004831: 52\n",
      "EFO_0003875: 2\n",
      "MONDO_0016820: 74\n",
      "HP_0030680: 1\n",
      "EFO_0005251: 0\n",
      "EFO_0004762: 114\n",
      "EFO_1001132: 13\n",
      "EFO_0000537: 961\n",
      "EFO_0008206: 61\n",
      "EFO_1001493: 3\n",
      "EFO_0021817: 6\n",
      "EFO_0007742: 116\n",
      "EFO_0008432: 3\n",
      "EFO_0006919: 15\n",
      "EFO_0004462: 1360\n",
      "EFO_0000668: 48\n",
      "EFO_0007741: 0\n",
      "EFO_0021815: 21\n",
      "EFO_0005095: 37\n",
      "EFO_0005278: 27\n",
      "EFO_0600025: 0\n",
      "EFO_0004985: 34\n",
      "EFO_0021816: 38\n",
      "EFO_0009276: 3\n",
      "EFO_0006920: 3\n",
      "EFO_0006791: 0\n",
      "EFO_ALLCHD: 38\n",
      "EFO_0008469: 28\n",
      "EFO_0010071: 521\n",
      "EFO_0009552: 242\n",
      "EFO_0004327: 1061\n",
      "EFO_1000881: 54\n",
      "EFO_0005037: 131\n",
      "EFO_0009184: 39\n",
      "EFO_0010556: 14\n",
      "EFO_0005094: 69\n",
      "EFO_0005243: 38\n",
      "EFO_0000275: 1124\n",
      "EFO_0001645: 42\n",
      "EFO_0006828: 17\n",
      "EFO_0009275: 2\n",
      "EFO_0008536: 3\n",
      "EFO_0001666: 7\n",
      "EFO_0007787: 13\n",
      "EFO_0004311: 73\n",
      "EFO_1001017: 17\n",
      "EFO_0008379: 26\n",
      "EFO_0005128: 136\n",
      "EFO_0005672: 31\n",
      "EFO_1000059: 2\n",
      "MONDO_0000153: 0\n",
      "EFO_0010272: 3\n",
      "EFO_0020942: 2\n",
      "EFO_0009285: 9\n",
      "EFO_0006522: 33\n",
      "MONDO_0019438: 31\n",
      "EFO_0004534: 120\n",
      "EFO_0003912: 12\n",
      "EFO_0006790: 28\n",
      "EFO_0004278: 39\n",
      "EFO_0007208: 4\n",
      "EFO_0008398: 14\n",
      "EFO_0000407: 65\n",
      "EFO_1000882: 5\n",
      "EFO_0003914: 16\n",
      "EFO_0005938: 45\n",
      "EFO_0009783: 58\n",
      "EFO_1001504: 71\n",
      "EFO_0005252: 5\n",
      "MONDO_0010679: 21\n",
      "EFO_0003870: 271\n",
      "EFO_1001857: 627\n",
      "MONDO_0005178: 548\n",
      "EFO_0004507: 66\n",
      "EFO_1001209: 39\n",
      "EFO_0000404: 19\n",
      "EFO_0004517: 89\n",
      "EFO_0005196: 1\n",
      "EFO_1001483: 35\n",
      "EFO_0004265: 329\n",
      "EFO_0007885: 767\n",
      "EFO_0000538: 176\n",
      "EFO_0009953: 3\n",
      "EFO_0021788: 135\n",
      "EFO_0004326: 450\n",
      "EFO_0021814: 11\n",
      "EFO_1001459: 25\n",
      "EFO_0003827: 13\n",
      "EFO_0008373: 70\n",
      "EFO_0000612: 954\n",
      "EFO_0007928: 95\n",
      "EFO_OBSTRUCTIVE: 13\n",
      "EFO_0004682: 1412\n",
      "EFO_0004573: 29\n",
      "EFO_0009277: 4\n",
      "EFO_0006903: 21\n",
      "EFO_0003144: 171\n",
      "EFO_1001482: 14\n",
      "MONDO_0005277: 910\n",
      "EFO_0004282: 39\n",
      "EFO_0004269: 45\n",
      "EFO_0004351: 377\n",
      "EFO_0020865: 640\n",
      "EFO_0006800: 0\n",
      "EFO_0600035: 3\n",
      "EFO_0010178: 102\n",
      "EFO_0008468: 7\n",
      "EFO_0006523: 6\n",
      "EFO_0008204: 57\n",
      "EFO_0004885: 36\n",
      "EFO_0005942: 0\n",
      "EFO_0000713: 4\n",
      "EFO_0004214: 90\n",
      "EFO_0005239: 21\n",
      "Orphanet_136: 0\n",
      "EFO_0005763: 4316\n",
      "MONDO_0002078: 0\n",
      "EFO_0009286: 6\n",
      "EFO_0004761: 1086\n",
      "EFO_LHLESION: 20\n",
      "EFO_0021787: 222\n",
      "EFO_NOS: 2\n",
      "EFO_0005269: 1\n",
      "EFO_0005207: 13\n",
      "EFO_0009185: 113\n",
      "EFO_0008205: 128\n",
      "EFO_0005524: 127\n",
      "EFO_0009551: 2\n",
      "EFO_0004718: 1\n",
      "EFO_0006902: 3\n",
      "MONDO_0001134: 88\n",
      "EFO_0005529: 23\n",
      "EFO_0008537: 10\n",
      "EFO_0004860: 43\n",
      "EFO_1000883: 6\n",
      "EFO_0004277: 5\n",
      "EFO_RHLESION: 0\n",
      "MONDO_0005475: 15\n",
      "EFO_0010273: 0\n",
      "EFO_0005939: 396\n",
      "EFO_1001161: 23\n",
      "MONDO_0015263: 62\n",
      "EFO_0004745: 6\n",
      "EFO_0006803: 0\n",
      "EFO_0006795: 0\n",
      "EFO_0004644: 91\n",
      "EFO_0000712: 344\n",
      "EFO_0600077: 1\n",
      "EFO_0004578: 54\n",
      "EFO_0005126: 1\n",
      "EFO_0006501: 116\n",
      "EFO_0004789: 4\n",
      "EFO_0008365: 3\n",
      "EFO_0001425: 3\n",
      "EFO_0008003: 99\n",
      "EFO_1002000: 4\n",
      "EFO_1002006: 31\n",
      "EFO_0009289: 4\n",
      "EFO_0005918: 10\n",
      "EFO_0004328: 19\n",
      "EFO_VASCULAR: 3\n",
      "EFO_0004791: 422\n",
      "EFO_0005053: 4\n",
      "EFO_0006900: 4\n",
      "EFO_0010600: 12\n",
      "EFO_0005054: 207\n",
      "EFO_0000717: 250\n",
      "EFO_0005043: 480\n"
     ]
    }
   ],
   "source": [
    "# Show number of SNPs falling in peaks, for each trait\n",
    "\n",
    "efo_ids_to_drop=[]\n",
    "\n",
    "for efo_id in efo_ids:\n",
    "    print(efo_id+': '+str(sum(all_peaks[efo_id])))\n",
    "    if sum(all_peaks[efo_id]) == 0:\n",
    "        efo_ids_to_drop.append(efo_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-three",
   "metadata": {},
   "source": [
    "### Drop any phenotypes for which there are no SNP-containing peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "million-immigration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proceed with: ['EFO_0010977', 'EFO_0004520', 'MONDO_0001823', 'EFO_0004286', 'EFO_0004519', 'EFO_0005527', 'EFO_0009952', 'EFO_0009609', 'EFO_0020101', 'EFO_1001976', 'HP_0001634', 'EFO_0009094', 'EFO_0005416', 'EFO_0005055', 'EFO_0005532', 'EFO_0001361', 'EFO_0005669', 'EFO_0000266', 'MONDO_0005090', 'EFO_0010820', 'EFO_0020863', 'EFO_0004831', 'EFO_0003875', 'MONDO_0016820', 'HP_0030680', 'EFO_0004762', 'EFO_1001132', 'EFO_0000537', 'EFO_0008206', 'EFO_1001493', 'EFO_0021817', 'EFO_0007742', 'EFO_0008432', 'EFO_0006919', 'EFO_0004462', 'EFO_0000668', 'EFO_0021815', 'EFO_0005095', 'EFO_0005278', 'EFO_0004985', 'EFO_0021816', 'EFO_0009276', 'EFO_0006920', 'EFO_ALLCHD', 'EFO_0008469', 'EFO_0010071', 'EFO_0009552', 'EFO_0004327', 'EFO_1000881', 'EFO_0005037', 'EFO_0009184', 'EFO_0010556', 'EFO_0005094', 'EFO_0005243', 'EFO_0000275', 'EFO_0001645', 'EFO_0006828', 'EFO_0009275', 'EFO_0008536', 'EFO_0001666', 'EFO_0007787', 'EFO_0004311', 'EFO_1001017', 'EFO_0008379', 'EFO_0005128', 'EFO_0005672', 'EFO_1000059', 'EFO_0010272', 'EFO_0020942', 'EFO_0009285', 'EFO_0006522', 'MONDO_0019438', 'EFO_0004534', 'EFO_0003912', 'EFO_0006790', 'EFO_0004278', 'EFO_0007208', 'EFO_0008398', 'EFO_0000407', 'EFO_1000882', 'EFO_0003914', 'EFO_0005938', 'EFO_0009783', 'EFO_1001504', 'EFO_0005252', 'MONDO_0010679', 'EFO_0003870', 'EFO_1001857', 'MONDO_0005178', 'EFO_0004507', 'EFO_1001209', 'EFO_0000404', 'EFO_0004517', 'EFO_0005196', 'EFO_1001483', 'EFO_0004265', 'EFO_0007885', 'EFO_0000538', 'EFO_0009953', 'EFO_0021788', 'EFO_0004326', 'EFO_0021814', 'EFO_1001459', 'EFO_0003827', 'EFO_0008373', 'EFO_0000612', 'EFO_0007928', 'EFO_OBSTRUCTIVE', 'EFO_0004682', 'EFO_0004573', 'EFO_0009277', 'EFO_0006903', 'EFO_0003144', 'EFO_1001482', 'MONDO_0005277', 'EFO_0004282', 'EFO_0004269', 'EFO_0004351', 'EFO_0020865', 'EFO_0600035', 'EFO_0010178', 'EFO_0008468', 'EFO_0006523', 'EFO_0008204', 'EFO_0004885', 'EFO_0000713', 'EFO_0004214', 'EFO_0005239', 'EFO_0005763', 'EFO_0009286', 'EFO_0004761', 'EFO_LHLESION', 'EFO_0021787', 'EFO_NOS', 'EFO_0005269', 'EFO_0005207', 'EFO_0009185', 'EFO_0008205', 'EFO_0005524', 'EFO_0009551', 'EFO_0004718', 'EFO_0006902', 'MONDO_0001134', 'EFO_0005529', 'EFO_0008537', 'EFO_0004860', 'EFO_1000883', 'EFO_0004277', 'MONDO_0005475', 'EFO_0005939', 'EFO_1001161', 'MONDO_0015263', 'EFO_0004745', 'EFO_0004644', 'EFO_0000712', 'EFO_0600077', 'EFO_0004578', 'EFO_0005126', 'EFO_0006501', 'EFO_0004789', 'EFO_0008365', 'EFO_0001425', 'EFO_0008003', 'EFO_1002000', 'EFO_1002006', 'EFO_0009289', 'EFO_0005918', 'EFO_0004328', 'EFO_VASCULAR', 'EFO_0004791', 'EFO_0005053', 'EFO_0006900', 'EFO_0010600', 'EFO_0005054', 'EFO_0000717', 'EFO_0005043']\n"
     ]
    }
   ],
   "source": [
    "efo_ids=[efo_id for efo_id in efo_ids if efo_id not in efo_ids_to_drop]\n",
    "print('proceed with: '+str(efo_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-madagascar",
   "metadata": {},
   "source": [
    "# Make a table of peaks x cell for each cell type, binarise using a threshold, then make 1000 permutations, then overwrite the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "executed-territory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT generating binarised matrix for MAIT-like since it already exists\n",
      "NOT generating binarised matrix for B since it already exists\n",
      "NOT generating binarised matrix for PC1_vent since it already exists\n",
      "NOT generating binarised matrix for CD8posT_cytox since it already exists\n",
      "NOT generating binarised matrix for B_plasma since it already exists\n",
      "NOT generating binarised matrix for LYVE1posMP_cycling since it already exists\n",
      "NOT generating binarised matrix for FB3 since it already exists\n",
      "NOT generating binarised matrix for PC2_atria since it already exists\n",
      "NOT generating binarised matrix for AVN_bundle_cell since it already exists\n",
      "NOT generating binarised matrix for Adip3 since it already exists\n",
      "NOT generating binarised matrix for EC8_ln since it already exists\n",
      "NOT generating binarised matrix for PC3_str since it already exists\n",
      "NOT generating binarised matrix for CD8posT_trans since it already exists\n",
      "NOT generating binarised matrix for aCM2 since it already exists\n",
      "NOT generating binarised matrix for SMC2_art since it already exists\n",
      "NOT generating binarised matrix for DC since it already exists\n",
      "NOT generating binarised matrix for T_or_NK_cycling since it already exists\n",
      "NOT generating binarised matrix for SAN_P_cell since it already exists\n",
      "NOT generating binarised matrix for EC3_cap since it already exists\n",
      "NOT generating binarised matrix for EC5_art since it already exists\n",
      "NOT generating binarised matrix for CD8posT_em since it already exists\n",
      "NOT generating binarised matrix for vCM3_stressed since it already exists\n",
      "NOT generating binarised matrix for EC4_immune since it already exists\n",
      "NOT generating binarised matrix for NK_CD16hi since it already exists\n",
      "NOT generating binarised matrix for NC2_glial_NGFpos since it already exists\n",
      "NOT generating binarised matrix for EC10_CMC-like since it already exists\n",
      "NOT generating binarised matrix for ILC since it already exists\n",
      "NOT generating binarised matrix for vCM4 since it already exists\n",
      "NOT generating binarised matrix for aCM4 since it already exists\n",
      "NOT generating binarised matrix for aCM3 since it already exists\n",
      "NOT generating binarised matrix for LYVE1posIGF1posMP since it already exists\n",
      "NOT generating binarised matrix for vCM1 since it already exists\n",
      "NOT generating binarised matrix for aCM1 since it already exists\n",
      "NOT generating binarised matrix for FB1 since it already exists\n",
      "NOT generating binarised matrix for EC2_cap since it already exists\n",
      "NOT generating binarised matrix for NK_CD56hi since it already exists\n",
      "NOT generating binarised matrix for Purkinje_cell since it already exists\n",
      "NOT generating binarised matrix for AVN_P_cell since it already exists\n",
      "NOT generating binarised matrix for NC1_glial since it already exists\n",
      "NOT generating binarised matrix for Adip1 since it already exists\n",
      "NOT generating binarised matrix for PC4_CMC-like since it already exists\n",
      "NOT generating binarised matrix for EC1_cap since it already exists\n",
      "NOT generating binarised matrix for Meso since it already exists\n",
      "NOT generating binarised matrix for LYVE1posTIMD4posMP since it already exists\n",
      "NOT generating binarised matrix for SMC1_basic since it already exists\n",
      "NOT generating binarised matrix for vCM2 since it already exists\n",
      "NOT generating binarised matrix for FB6 since it already exists\n",
      "NOT generating binarised matrix for MoMP since it already exists\n",
      "NOT generating binarised matrix for FB4_activated since it already exists\n",
      "NOT generating binarised matrix for FB5 since it already exists\n",
      "NOT generating binarised matrix for EC6_ven since it already exists\n",
      "NOT generating binarised matrix for CD4posT_naive since it already exists\n",
      "NOT generating binarised matrix for CD16posMo since it already exists\n",
      "NOT generating binarised matrix for EC7_endocardial since it already exists\n",
      "NOT generating binarised matrix for CD14posMo since it already exists\n",
      "NOT generating binarised matrix for Adip2 since it already exists\n",
      "NOT generating binarised matrix for CD8posT_te since it already exists\n",
      "NOT generating binarised matrix for FB2 since it already exists\n",
      "NOT generating binarised matrix for Mast since it already exists\n",
      "NOT generating binarised matrix for CD4posT_act since it already exists\n",
      "finished\n",
      "CPU times: user 4.35 ms, sys: 41 Âµs, total: 4.39 ms\n",
      "Wall time: 106 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# makes cell x peak matrix, including 1000 permutations\n",
    "# NB the SNPs in peaks file needs is specific to the defined set of peaks, which will vary accoring to threshold for binarisation, so this all peaks file needs to be saved according to threshold used\n",
    "\n",
    "permutations=range(n_permutations)\n",
    "\n",
    "bin_mat_path='/nfs/team205/heart/JC_SNP_enrichment/8region/EBI_GWAS/binarised_permutation_matrices/'\n",
    "\n",
    "os.makedirs(bin_mat_path,\n",
    "           exist_ok=True) # makes the directory\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    if os.path.isfile(f'{bin_mat_path}{cell_type}_{n_permutations}_permutations_bin_threshold_{threshold_for_filename}_matrix.csv') == False:\n",
    "\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        print(f'{current_time}...generating binarised matrix for {cell_type}...')\n",
    "\n",
    "        cell_df=pd.DataFrame(peaks.loc[cell_type])\n",
    "        cell_df['peak'] = cell_df.index\n",
    "        cell_df['chrom']=cell_df['peak'].str.split(':',expand=True)[0]\n",
    "        cell_df['peak_window']=cell_df['peak'].str.split(':',expand=True)[1]\n",
    "        cell_df['start']=cell_df['peak_window'].str.split('_',expand=True)[0].astype(int)\n",
    "        cell_df['end']=cell_df['peak_window'].str.split('_',expand=True)[1].astype(int)\n",
    "        cell_df[f'{cell_type}_binarised_real']=cell_df[cell_type].ge(threshold).astype(int)\n",
    "\n",
    "        for permutation in permutations:\n",
    "            cell_df[f'{cell_type}_binarised_permutation_{permutation}'] = np.random.permutation(cell_df[f'{cell_type}_binarised_real'])\n",
    "        cell_df=cell_df.filter(regex=cell_type+'_')\n",
    "        cell_df.to_csv(f'{bin_mat_path}{cell_type}_{n_permutations}_permutations_bin_threshold_{threshold_for_filename}_matrix.csv',index=True)\n",
    "    else:\n",
    "        print(f'NOT generating binarised matrix for {cell_type} since it already exists')\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-strand",
   "metadata": {},
   "source": [
    "# Read in Binarised Matrix for each cell type, join it to the all_peaks file which has trait info (binding on the index [peaks]), then save these joined binarised matrix files (now with added trait info) in a different directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "empirical-metropolitan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT generating joined binarised matrix for MAIT-like since it already exists\n",
      "NOT generating joined binarised matrix for B since it already exists\n",
      "NOT generating joined binarised matrix for PC1_vent since it already exists\n",
      "NOT generating joined binarised matrix for CD8posT_cytox since it already exists\n",
      "NOT generating joined binarised matrix for B_plasma since it already exists\n",
      "NOT generating joined binarised matrix for LYVE1posMP_cycling since it already exists\n",
      "NOT generating joined binarised matrix for FB3 since it already exists\n",
      "NOT generating joined binarised matrix for PC2_atria since it already exists\n",
      "NOT generating joined binarised matrix for AVN_bundle_cell since it already exists\n",
      "NOT generating joined binarised matrix for Adip3 since it already exists\n",
      "NOT generating joined binarised matrix for EC8_ln since it already exists\n",
      "NOT generating joined binarised matrix for PC3_str since it already exists\n",
      "NOT generating joined binarised matrix for CD8posT_trans since it already exists\n",
      "NOT generating joined binarised matrix for aCM2 since it already exists\n",
      "NOT generating joined binarised matrix for SMC2_art since it already exists\n",
      "NOT generating joined binarised matrix for DC since it already exists\n",
      "NOT generating joined binarised matrix for T_or_NK_cycling since it already exists\n",
      "NOT generating joined binarised matrix for SAN_P_cell since it already exists\n",
      "NOT generating joined binarised matrix for EC3_cap since it already exists\n",
      "NOT generating joined binarised matrix for EC5_art since it already exists\n",
      "NOT generating joined binarised matrix for CD8posT_em since it already exists\n",
      "NOT generating joined binarised matrix for vCM3_stressed since it already exists\n",
      "NOT generating joined binarised matrix for EC4_immune since it already exists\n",
      "NOT generating joined binarised matrix for NK_CD16hi since it already exists\n",
      "NOT generating joined binarised matrix for NC2_glial_NGFpos since it already exists\n",
      "NOT generating joined binarised matrix for EC10_CMC-like since it already exists\n",
      "NOT generating joined binarised matrix for ILC since it already exists\n",
      "NOT generating joined binarised matrix for vCM4 since it already exists\n",
      "NOT generating joined binarised matrix for aCM4 since it already exists\n",
      "NOT generating joined binarised matrix for aCM3 since it already exists\n",
      "NOT generating joined binarised matrix for LYVE1posIGF1posMP since it already exists\n",
      "NOT generating joined binarised matrix for vCM1 since it already exists\n",
      "NOT generating joined binarised matrix for aCM1 since it already exists\n",
      "NOT generating joined binarised matrix for FB1 since it already exists\n",
      "NOT generating joined binarised matrix for EC2_cap since it already exists\n",
      "NOT generating joined binarised matrix for NK_CD56hi since it already exists\n",
      "NOT generating joined binarised matrix for Purkinje_cell since it already exists\n",
      "NOT generating joined binarised matrix for AVN_P_cell since it already exists\n",
      "NOT generating joined binarised matrix for NC1_glial since it already exists\n",
      "NOT generating joined binarised matrix for Adip1 since it already exists\n",
      "NOT generating joined binarised matrix for PC4_CMC-like since it already exists\n",
      "NOT generating joined binarised matrix for EC1_cap since it already exists\n",
      "NOT generating joined binarised matrix for Meso since it already exists\n",
      "NOT generating joined binarised matrix for LYVE1posTIMD4posMP since it already exists\n",
      "NOT generating joined binarised matrix for SMC1_basic since it already exists\n",
      "NOT generating joined binarised matrix for vCM2 since it already exists\n",
      "NOT generating joined binarised matrix for FB6 since it already exists\n",
      "NOT generating joined binarised matrix for MoMP since it already exists\n",
      "NOT generating joined binarised matrix for FB4_activated since it already exists\n",
      "NOT generating joined binarised matrix for FB5 since it already exists\n",
      "NOT generating joined binarised matrix for EC6_ven since it already exists\n",
      "NOT generating joined binarised matrix for CD4posT_naive since it already exists\n",
      "NOT generating joined binarised matrix for CD16posMo since it already exists\n",
      "NOT generating joined binarised matrix for EC7_endocardial since it already exists\n",
      "NOT generating joined binarised matrix for CD14posMo since it already exists\n",
      "NOT generating joined binarised matrix for Adip2 since it already exists\n",
      "NOT generating joined binarised matrix for CD8posT_te since it already exists\n",
      "NOT generating joined binarised matrix for FB2 since it already exists\n",
      "NOT generating joined binarised matrix for Mast since it already exists\n",
      "NOT generating joined binarised matrix for CD4posT_act since it already exists\n",
      "finished\n",
      "CPU times: user 3.49 ms, sys: 3.99 ms, total: 7.48 ms\n",
      "Wall time: 94.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "joined_bin_mat_path='/nfs/team205/heart/JC_SNP_enrichment/8region/EBI_GWAS/binarised_permutation_matrices_joined_incremental/'\n",
    "\n",
    "os.makedirs(joined_bin_mat_path,\n",
    "           exist_ok=True) # makes the directory\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    if os.path.isfile(f'{joined_bin_mat_path}{cell_type}_{n_permutations}_permutations_for_{n_traits}_traits_bin_threshold_{threshold_for_filename}_matrix_joined.csv') == False:    \n",
    "        \n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(f'{current_time}: {cell_type}: making bin matrix with trait for this cell')\n",
    "\n",
    "        # read in binary matrices which have already been made\n",
    "        binarised_matrix=pd.read_csv(f'{bin_mat_path}{cell_type}_{n_permutations}_permutations_bin_threshold_{threshold_for_filename}_matrix.csv')\n",
    "\n",
    "        # tidy and add the columns we need\n",
    "        binarised_matrix.rename(columns = {'Unnamed: 0':'peak'}, inplace = True)\n",
    "        binarised_matrix=binarised_matrix.set_index(binarised_matrix.iloc[:,0])\n",
    "        binarised_matrix=binarised_matrix.drop(columns=['peak'])\n",
    "        \n",
    "        # add on the columns indicating whether SNPs are in peaks\n",
    "        binarised_matrix=binarised_matrix.join(all_peaks)\n",
    "\n",
    "        # save this modified binary matrix to a separate directory\n",
    "        binarised_matrix.to_csv(f'{joined_bin_mat_path}{cell_type}_{n_permutations}_permutations_for_{n_traits}_traits_bin_threshold_{threshold_for_filename}_matrix_joined.csv')\n",
    "    else:\n",
    "        print(f'NOT generating joined binarised matrix for {cell_type} since it already exists')\n",
    "\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-ladder",
   "metadata": {},
   "source": [
    "# Calculate enrichment of cell types for different traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "coral-korean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...================================================================...\n",
      "...19:31:35:STARTING\n",
      "...================================================================...\n",
      "...evaluating 176 traits, across 60 cell types...\n",
      "...================================================================...\n",
      "...19:31:35: 60 of 60 cell types remaining. Reading binarised matrix for MAIT-like...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...19:40:25: 59 of 60 cell types remaining. Reading binarised matrix for B...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...19:49:06: 58 of 60 cell types remaining. Reading binarised matrix for PC1_vent...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...19:59:37: 57 of 60 cell types remaining. Reading binarised matrix for CD8posT_cytox...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...20:08:01: 56 of 60 cell types remaining. Reading binarised matrix for B_plasma...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...20:18:19: 55 of 60 cell types remaining. Reading binarised matrix for LYVE1posMP_cycling...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...20:30:26: 54 of 60 cell types remaining. Reading binarised matrix for FB3...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...20:42:33: 53 of 60 cell types remaining. Reading binarised matrix for PC2_atria...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...20:52:34: 52 of 60 cell types remaining. Reading binarised matrix for AVN_bundle_cell...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...21:11:45: 51 of 60 cell types remaining. Reading binarised matrix for Adip3...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...21:30:07: 50 of 60 cell types remaining. Reading binarised matrix for EC8_ln...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...21:40:59: 49 of 60 cell types remaining. Reading binarised matrix for PC3_str...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...21:51:40: 48 of 60 cell types remaining. Reading binarised matrix for CD8posT_trans...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...21:59:28: 47 of 60 cell types remaining. Reading binarised matrix for aCM2...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...22:17:50: 46 of 60 cell types remaining. Reading binarised matrix for SMC2_art...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...22:29:32: 45 of 60 cell types remaining. Reading binarised matrix for DC...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...22:41:11: 44 of 60 cell types remaining. Reading binarised matrix for T_or_NK_cycling...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...22:52:39: 43 of 60 cell types remaining. Reading binarised matrix for SAN_P_cell...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...23:12:00: 42 of 60 cell types remaining. Reading binarised matrix for EC3_cap...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...23:21:34: 41 of 60 cell types remaining. Reading binarised matrix for EC5_art...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...23:31:37: 40 of 60 cell types remaining. Reading binarised matrix for CD8posT_em...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...23:39:45: 39 of 60 cell types remaining. Reading binarised matrix for vCM3_stressed...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...00:01:59: 38 of 60 cell types remaining. Reading binarised matrix for EC4_immune...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...00:11:17: 37 of 60 cell types remaining. Reading binarised matrix for NK_CD16hi...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...00:20:13: 36 of 60 cell types remaining. Reading binarised matrix for NC2_glial_NGFpos...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...00:34:46: 35 of 60 cell types remaining. Reading binarised matrix for EC10_CMC-like...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...00:44:30: 34 of 60 cell types remaining. Reading binarised matrix for ILC...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...00:55:53: 33 of 60 cell types remaining. Reading binarised matrix for vCM4...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...01:15:16: 32 of 60 cell types remaining. Reading binarised matrix for aCM4...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...01:31:15: 31 of 60 cell types remaining. Reading binarised matrix for aCM3...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...01:45:23: 30 of 60 cell types remaining. Reading binarised matrix for LYVE1posIGF1posMP...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...01:55:45: 29 of 60 cell types remaining. Reading binarised matrix for vCM1...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...02:13:05: 28 of 60 cell types remaining. Reading binarised matrix for aCM1...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...02:26:02: 27 of 60 cell types remaining. Reading binarised matrix for FB1...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...02:37:53: 26 of 60 cell types remaining. Reading binarised matrix for EC2_cap...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...02:47:58: 25 of 60 cell types remaining. Reading binarised matrix for NK_CD56hi...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...02:57:44: 24 of 60 cell types remaining. Reading binarised matrix for Purkinje_cell...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...03:21:28: 23 of 60 cell types remaining. Reading binarised matrix for AVN_P_cell...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...03:40:55: 22 of 60 cell types remaining. Reading binarised matrix for NC1_glial...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...03:50:29: 21 of 60 cell types remaining. Reading binarised matrix for Adip1...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...04:04:41: 20 of 60 cell types remaining. Reading binarised matrix for PC4_CMC-like...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...04:22:39: 19 of 60 cell types remaining. Reading binarised matrix for EC1_cap...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...04:32:46: 18 of 60 cell types remaining. Reading binarised matrix for Meso...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...04:44:12: 17 of 60 cell types remaining. Reading binarised matrix for LYVE1posTIMD4posMP...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...04:54:04: 16 of 60 cell types remaining. Reading binarised matrix for SMC1_basic...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...05:04:52: 15 of 60 cell types remaining. Reading binarised matrix for vCM2...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...05:23:51: 14 of 60 cell types remaining. Reading binarised matrix for FB6...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...05:36:02: 13 of 60 cell types remaining. Reading binarised matrix for MoMP...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...05:46:03: 12 of 60 cell types remaining. Reading binarised matrix for FB4_activated...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...05:57:19: 11 of 60 cell types remaining. Reading binarised matrix for FB5...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...06:09:43: 10 of 60 cell types remaining. Reading binarised matrix for EC6_ven...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...06:19:36: 9 of 60 cell types remaining. Reading binarised matrix for CD4posT_naive...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...06:27:45: 8 of 60 cell types remaining. Reading binarised matrix for CD16posMo...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...06:37:21: 7 of 60 cell types remaining. Reading binarised matrix for EC7_endocardial...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...06:47:35: 6 of 60 cell types remaining. Reading binarised matrix for CD14posMo...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...06:57:12: 5 of 60 cell types remaining. Reading binarised matrix for Adip2...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...07:14:44: 4 of 60 cell types remaining. Reading binarised matrix for CD8posT_te...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...07:21:55: 3 of 60 cell types remaining. Reading binarised matrix for FB2...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...07:34:54: 2 of 60 cell types remaining. Reading binarised matrix for Mast...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...07:39:50: 1 of 60 cell types remaining. Reading binarised matrix for CD4posT_act...\n",
      "...================================================================...\n",
      "...================================================================...\n",
      "...07:48:00:FINSIHED\n",
      "...================================================================...\n",
      "CPU times: user 12h 1min 27s, sys: 6min 19s, total: 12h 7min 47s\n",
      "Wall time: 12h 16min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "\n",
    "\n",
    "# Find the proportion of all peaks which are open in this celltype\n",
    "\n",
    "output_path='/nfs/team205/heart/JC_SNP_enrichment/8region/EBI_GWAS/enrichment_output/'\n",
    "\n",
    "os.makedirs(output_path,\n",
    "           exist_ok=True) # makes the directory\n",
    "\n",
    "list_of_output_dfs=[]\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(f'...================================================================...') \n",
    "print(f'...{current_time}:STARTING')\n",
    "print(f'...================================================================...') \n",
    "\n",
    "# make some empty lists\n",
    "proportion_of_SNPs_found_in_celltype_specific_open_peaks=[]\n",
    "proportion_of_all_open_peaks_found_in_this_celltype=[]\n",
    "\n",
    "n_times_proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion=[]\n",
    "mean_proportions_of_SNPs_in_open_peaks=[]\n",
    "p_values=[]\n",
    "efo_id_list=[]\n",
    "efo_term_list=[]\n",
    "cell_type_list=[]\n",
    "n_SNPs_list=[]\n",
    "\n",
    "cell_types_done=[]\n",
    "n_cell_types_total=len(cell_types)\n",
    "\n",
    "permutations=range(n_permutations)\n",
    "\n",
    "print('...evaluating '+str(len(efo_ids))+' traits, across '+str(len(cell_types))+' cell types...')\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        cell_types_done.append(cell_type)\n",
    "        n_cell_types_done=len(cell_types_done)\n",
    "        n_cell_types_remaining=n_cell_types_total-n_cell_types_done\n",
    "\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(f'...================================================================...')    \n",
    "        print(f'...{current_time}: {n_cell_types_remaining+1} of {n_cell_types_total} cell types remaining. Reading binarised matrix for {cell_type}...')\n",
    "        print(f'...================================================================...') \n",
    "\n",
    "        cell_bin_mat=pd.read_csv(f'{joined_bin_mat_path}{cell_type}_{n_permutations}_permutations_for_{n_traits}_traits_bin_threshold_{threshold_for_filename}_matrix_joined.csv',index_col='peak')\n",
    "\n",
    "        prop_bins_in_this_cell_type=(len(cell_bin_mat[cell_bin_mat[f'{cell_type}_binarised_real']==1]))/len(cell_bin_mat)\n",
    "\n",
    "\n",
    "        for efo_id in efo_ids:\n",
    "\n",
    "            # grab some metadata\n",
    "            efo_term=SNP_md.loc[efo_id]['efo_term']\n",
    "            n_SNPs=SNP_md.loc[efo_id]['n_SNPs']\n",
    "\n",
    "            # add columns which won't change until we run a new cell_type\n",
    "            proportion_of_all_open_peaks_found_in_this_celltype.append(prop_bins_in_this_cell_type)\n",
    "            cell_type_list.append(cell_type)\n",
    "\n",
    "            # add columns which won't change until we run a new efo_id\n",
    "            n_SNPs_list.append(n_SNPs)\n",
    "            efo_id_list.append(efo_id)\n",
    "            efo_term_list.append(efo_term)\n",
    "\n",
    "            # subset to just open regions for this cell type\n",
    "            # find the proportion of SNPs for this trait that lie within this cell types open peaks\n",
    "            observed_proportion=(cell_bin_mat[efo_id][cell_bin_mat[f'{cell_type}_binarised_real']==1].sum())/(cell_bin_mat[efo_id].sum())\n",
    "\n",
    "            proportion_of_SNPs_found_in_celltype_specific_open_peaks.append(observed_proportion)\n",
    "\n",
    "            proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks=[]\n",
    "\n",
    "            for permutation in permutations:\n",
    "                proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks.append(cell_bin_mat[efo_id][cell_bin_mat[f'{cell_type}_binarised_permutation_{permutation}']==1].sum()/cell_bin_mat[efo_id].sum())\n",
    "\n",
    "            proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion = [i for i in proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks if i >= observed_proportion]\n",
    "\n",
    "            n_times_proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion.append(len(proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion))\n",
    "\n",
    "            p_values.append(len(proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion)/len(permutations)) # p val is simply the proportion of null hypotheses 'observations' greater than the actual observed proportion\n",
    "\n",
    "            mean_proportions_of_SNPs_in_open_peaks.append(sum(proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks)/len(proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks))\n",
    "\n",
    "            # Plot histograms for each cell type\n",
    "    #        plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    #        plt.rcParams[\"figure.dpi\"] = 300\n",
    "\n",
    "    #        plt.hist(proportion_of_SNPs_found_in_permutations_of_celltype_specific_open_peaks,\n",
    "    #                 bins=100,color='red',\n",
    "    #                 range=(0,1),\n",
    "    #                 histtype='stepfilled',edgecolor='none')\n",
    "    #        plt.axvline(x=observed_proportion, color='blue', linestyle='--')\n",
    "    #        plt.legend(['null: proportion of SNPs falling in randomly shuffled OC regions','observed: proportion of SNPs falling cell-type specific OC regions'])\n",
    "    #        plt.title('cell type: '+cell_type+', trait: '+efo_id+', term: '+efo_term+', threshold for binarisation: '+threshold_for_filename)\n",
    "    #        plt.savefig(f'{output_path}{efo_id}_{efo_term}_{cell_type}_{threshold_for_filename}_SNP_enrichment.png')\n",
    "    #        plt.clf() #clears the current plot\n",
    "\n",
    "    \n",
    "    except KeyError as e:\n",
    "        # Log the error\n",
    "        logging.error(e)\n",
    "        print(cell_type)\n",
    "\n",
    "    # edited so that the file is written incrementally\n",
    "        \n",
    "    output_dict={\n",
    "        'cell_type':cell_type_list,\n",
    "        'proportion_of_all_open_peaks_found_in_this_celltype':proportion_of_all_open_peaks_found_in_this_celltype,\n",
    "        'proportion_of_SNPs_found_in_celltype_specific_open_peaks':proportion_of_SNPs_found_in_celltype_specific_open_peaks,\n",
    "        'mean_proportions_of_SNPs_in_open_peaks':mean_proportions_of_SNPs_in_open_peaks,\n",
    "        'n_times_proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion':n_times_proportions_of_SNPs_in_permuted_open_peaks_greater_than_observed_proportion,\n",
    "        'p_value':p_values,\n",
    "        'n_SNPs':n_SNPs_list,\n",
    "        'efo_id':efo_id_list,\n",
    "        'efo_term':efo_term_list}\n",
    "\n",
    "    output_df=pd.DataFrame(output_dict)\n",
    "\n",
    "    list_of_output_dfs.append(output_df)\n",
    "    combined_output_df=pd.concat(list_of_output_dfs)\n",
    "    combined_output_df=combined_output_df.sort_values(by=['efo_id'])\n",
    "    combined_output_df=combined_output_df.set_index('cell_type')\n",
    "    combined_output_df.to_csv(f'{output_path}{threshold_for_filename}_{window_size_for_filename}_SNPs_in_LD{LD_threshold_for_filename}_all_traits_summary.csv')\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(f'...================================================================...')    \n",
    "print(f'...{current_time}:FINSIHED')\n",
    "print(f'...================================================================...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-premiere",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scanpy",
   "language": "python",
   "name": "scanpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
